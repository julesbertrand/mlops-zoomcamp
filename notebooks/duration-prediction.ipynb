{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nervous-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet, ElasticNetCV\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "sophisticated-ottawa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fhv_tripdata_2021-01.parquet    green_tripdata_2021-02.parquet\n",
      "fhv_tripdata_2021-02.parquet    green_tripdata_2022-01.parquet\n",
      "green_tripdata_2021-01.parquet\n"
     ]
    }
   ],
   "source": [
    "ls ../data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-designation",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "purple-development",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1154112, 8)\n",
      "19.167224093791006\n",
      "(1037692, 8)\n",
      "20.706986225199763\n"
     ]
    }
   ],
   "source": [
    "train_set_filepath = \"../data/fhv_tripdata_2021-01.parquet\"\n",
    "val_set_filepath = \"../data/fhv_tripdata_2021-02.parquet\"\n",
    "\n",
    "\n",
    "dfs = []\n",
    "for filepath in [train_set_filepath, val_set_filepath]:\n",
    "    df = pd.read_parquet(filepath)\n",
    "    \n",
    "    df[\"duration\"] = df.dropOff_datetime - df.pickup_datetime\n",
    "    df[\"duration\"] = df[\"duration\"].dt.total_seconds() / 60\n",
    "    \n",
    "    print(df.shape)\n",
    "    print(df.duration.mean())\n",
    "    \n",
    "    df_prepared = df.query(\"1 <= duration <= 60\").copy()\n",
    "    \n",
    "    categorical = ['PUlocationID', 'DOlocationID']\n",
    "\n",
    "    df_prepared[categorical] = df_prepared[categorical].astype(str)\n",
    "    \n",
    "    df_prepared[\"PU_DO\"] = df_prepared['PUlocationID'] + \"_\" + df_prepared['DOlocationID']\n",
    "    \n",
    "    dfs.append(df_prepared)\n",
    "\n",
    "df_train = dfs[0]\n",
    "df_val = dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "stone-angel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8453180949085712"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical = ['PUlocationID', 'DOlocationID']\n",
    "(df_train[categorical] == \"nan\").any(axis=1).sum() / len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "sunset-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numerical = [\"trip_distance\"]\n",
    "target = \"duration\"\n",
    "\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical].to_dict(orient=\"records\")\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val[categorical].to_dict(orient=\"records\")\n",
    "X_val = dv.transform(val_dicts)\n",
    "\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "photographic-complexity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1109826x525 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2219652 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "hazardous-marine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.014286566178097"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "mean_squared_error(y_val, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = Lasso(alpha=0.01)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "mean_squared_error(y_val, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = ElasticNet()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "mean_squared_error(y_val, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ff.create_distplot([y_pred, y_val], group_labels=[\"prediction\", \"actual\"])\n",
    "fig.update_layout(\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-start",
   "metadata": {},
   "source": [
    "## Pipelining with Kedro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "linear-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filepath):    \n",
    "    df = pd.read_parquet(filepath)\n",
    "    return df\n",
    "\n",
    "\n",
    "def prepare_data(df):\n",
    "    df[\"duration\"] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df[\"duration\"] = df[\"duration\"].dt.total_seconds() / 60\n",
    "\n",
    "    df_prepared = df.query(\"1 <= duration <= 60\").copy()\n",
    "    \n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "\n",
    "    df_prepared[categorical] = df_prepared[categorical].astype(str)\n",
    "    \n",
    "    df_prepared[\"PU_DO\"] = df_prepared['PULocationID'] + \"_\" + df_prepared['DOLocationID']\n",
    "    \n",
    "    return df_prepared\n",
    "\n",
    "def to_records(df):\n",
    "    return df.to_dict(orient=\"records\")\n",
    "\n",
    "\n",
    "def get_X_y(df, features, target):\n",
    "    return df[features], df[target]\n",
    "\n",
    "def train_model(X_train, y_train, model_type: str = \"lr\"):\n",
    "    if model_type == \"lr\":\n",
    "        model = LinearRegression()\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    p = Pipeline(\n",
    "        [\n",
    "            (\"torecords\", FunctionTransformer(to_records)),\n",
    "            (\"vectorizer\", DictVectorizer()),\n",
    "            (\"model\", model)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    p.fit(X_train, y_train)\n",
    "    \n",
    "    return p\n",
    "\n",
    "def predict(model, X):\n",
    "    return model.predict(X)\n",
    "\n",
    "\n",
    "def evaluate_model(y_val, y_pred):\n",
    "    metrics = {\"rmse\":  mean_squared_error(y_val, y_pred, squared=False)}\n",
    "    return metrics\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "elect-representation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 10.499110710078236}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = \"duration\"\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "numerical = [\"trip_distance\"]\n",
    "features = categorical + numerical\n",
    "\n",
    "df_train = read_dataframe(\"../data/green_tripdata_2021-01.parquet\")\n",
    "df_val = read_dataframe(\"../data/green_tripdata_2021-02.parquet\")\n",
    "\n",
    "df_train = prepare_data(df_train)\n",
    "df_val = prepare_data(df_val)\n",
    "\n",
    "X_train, y_train = get_X_y(df_train, features, target)\n",
    "X_val, y_val = get_X_y(df_val, features, target)\n",
    "\n",
    "model = train_model(X_train, y_train)\n",
    "\n",
    "y_pred = predict(model, X_val)\n",
    "\n",
    "metrics =  evaluate_model(y_val, y_pred)\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "correct-mouth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline([\n",
       "Node(prepare_data, {'df': 'training_set'}, 'df_prepared', None),\n",
       "Node(prepare_data, {'df': 'validation_set'}, 'df_prepared_inference', None),\n",
       "Node(get_X_y, {'df': 'df_prepared_inference', 'features': 'params:FEATURES', 'target': 'params:TARGET'}, ['X', 'y'], None),\n",
       "Node(get_X_y, {'df': 'df_prepared', 'features': 'params:FEATURES', 'target': 'params:TARGET'}, ['X_train', 'y_train'], None),\n",
       "Node(train_model, ['X_train', 'y_train'], 'model', None),\n",
       "Node(predict, {'model': 'model', 'X': 'X'}, 'y_pred', None),\n",
       "Node(evaluate_model, {'y_pred': 'y_pred', 'y_val': 'y'}, 'metrics', None)\n",
       "])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kedro.pipeline import pipeline, node\n",
    "\n",
    "\n",
    "training_pipeline = pipeline(\n",
    "    [\n",
    "        node(prepare_data, inputs={\"df\": \"training_set\"}, outputs=\"df_prepared\"),\n",
    "        node(\n",
    "            get_X_y, \n",
    "            inputs={\n",
    "                \"df\": \"df_prepared\",\n",
    "                \"features\": \"params:FEATURES\", \n",
    "                \"target\": \"params:TARGET\"\n",
    "            },\n",
    "            outputs=[\"X_train\", \"y_train\"]\n",
    "        ),\n",
    "        node(\n",
    "            train_model,\n",
    "            inputs=[\"X_train\", \"y_train\"],\n",
    "            outputs=\"model\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "inference_pipeline = pipeline(\n",
    "    [\n",
    "        node(prepare_data, inputs={\"df\": \"inference_set\"}, outputs=\"df_prepared_inference\"),\n",
    "        node(\n",
    "            get_X_y, \n",
    "            inputs={\n",
    "                \"df\": \"df_prepared_inference\",\n",
    "                \"features\": \"params:FEATURES\", \n",
    "                \"target\": \"params:TARGET\"\n",
    "            },\n",
    "            outputs=[\"X\", \"y\"]\n",
    "        ),\n",
    "        node(\n",
    "            predict,\n",
    "            inputs={\"model\": \"model\", \"X\": \"X\"},\n",
    "            outputs=\"y_pred\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "evaluation_pipeline = pipeline(\n",
    "    [\n",
    "        inference_pipeline,\n",
    "        node(evaluate_model, inputs={\"y_pred\": \"y_pred\", \"y_val\": \"y\"}, outputs=\"metrics\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "training_and_evaluation_pipeline = pipeline(\n",
    "    training_pipeline + evaluation_pipeline,\n",
    "    inputs = {\"training_set\": \"training_set\", \"inference_set\": \"validation_set\"},\n",
    "    outputs=\"metrics\"\n",
    ")\n",
    "\n",
    "training_and_evaluation_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "invalid-armor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metrics': {'rmse': 9.838799799829626}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kedro.runner import SequentialRunner\n",
    "from kedro.io import DataCatalog\n",
    "from kedro.extras.datasets.pandas import ParquetDataSet\n",
    "\n",
    "runner = SequentialRunner()\n",
    "\n",
    "catalog = DataCatalog(\n",
    "    {\n",
    "        \"training_set\": ParquetDataSet(\"../data/green_tripdata_2021-01.parquet\"),\n",
    "        \"validation_set\": ParquetDataSet(\"../data/green_tripdata_2021-01.parquet\")\n",
    "    },\n",
    "    feed_dict = {\n",
    "        \"params:FEATURES\": features,\n",
    "        \"params:TARGET\": target\n",
    "    }\n",
    ")\n",
    "\n",
    "runner.run(training_and_evaluation_pipeline, catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-entrance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-zc",
   "language": "python",
   "name": "mlops-zc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
